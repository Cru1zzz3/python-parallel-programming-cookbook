{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Parallel Programming (Lab 6) - Udartsev Stanislav.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPJzWyweXeGHpFhDtT/znp6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cru1zzz3/python-parallel-programming-cookbook/blob/main/Python_Parallel_Programming_(Lab_6)_Udartsev_Stanislav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6IBhYGq5vYP"
      },
      "source": [
        "Проверяем версию компилятора NVIDIA CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avsaG-Oi5JoQ",
        "outputId": "6e877e73-85af-4ccd-8c5c-74efd6a1639c"
      },
      "source": [
        "!nvcc --version "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fydH8jO5Yxh",
        "outputId": "35135571-182f-490f-f433-42e9136cf382"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[?25l\r\u001b[K     |▏                               | 10 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |▍                               | 20 kB 31.0 MB/s eta 0:00:01\r\u001b[K     |▋                               | 30 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |▉                               | 40 kB 10.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 51 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 61 kB 6.1 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 71 kB 5.9 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 81 kB 6.6 MB/s eta 0:00:01\r\u001b[K     |█▊                              | 92 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |██                              | 102 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▏                             | 112 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 122 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 133 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 143 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███                             | 153 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 163 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▎                            | 174 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▌                            | 184 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███▊                            | 194 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 204 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████                            | 215 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▎                           | 225 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 235 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▊                           | 245 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 256 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████                           | 266 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 276 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 286 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 296 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 307 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████                          | 317 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 327 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 337 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 348 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 358 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 368 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 378 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 389 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 399 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 409 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████                        | 419 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 430 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 440 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 450 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 460 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 471 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 481 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 491 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 501 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 512 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 522 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 532 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 542 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 552 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 563 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 573 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 583 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 593 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 604 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 614 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 624 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 634 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 645 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 655 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 665 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 675 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 686 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 696 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 706 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 716 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 727 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 737 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 747 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 757 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 768 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 778 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 788 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 798 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 808 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 819 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 829 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 839 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 849 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 860 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 870 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 880 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 890 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 901 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 911 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 921 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 931 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 942 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 952 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 962 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 972 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 983 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 993 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 1.0 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 1.1 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 1.2 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 1.3 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.4 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 1.5 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.6 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.7 MB 5.4 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 4.1 MB/s \n",
            "\u001b[?25hCollecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.9.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=627577 sha256=fab00ebbd5cf1bcb74c709ea1a5bb86757d552620115240bde58665ee6ec4024\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.9-py2.py3-none-any.whl size=62370 sha256=8512d3fc973712b58d8a95599d3b6daf2f32ed6fa06fc7a1047c9081c1bf7b51\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/b9/6e/94bb014f6484b15ec77e7877f3a227609481ffd98db364504d\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.1.6 pycuda-2021.1 pytools-2021.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEGY9XPQx0jv"
      },
      "source": [
        "**Using the PyCUDA module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrYwwivT_-oE"
      },
      "source": [
        "Для того, чтобы инициализировать CUDA драйвер, необходимо сменить тип Runtime'a в Google Collab на тот, который поддерживает аппаратное ускорение GPU. \n",
        "Для этого необходимо: \n",
        "\n",
        "*   Нажать на вкладку `Runtime` и выбрать `Change runtime type`.\n",
        "*   После этого в разделе `Hardware Acceleration`, выбрать `GPU` и нажать `Save`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMUqConq5lrh",
        "outputId": "5061a0c1-bb79-4448-a567-9e9d7b7861f9"
      },
      "source": [
        "import pycuda.driver as drv \n",
        "drv.init() \n",
        "print(\"%d device(s) found.\" % drv.Device.count()) \n",
        "for ordinal in range(drv.Device.count()): \n",
        "  dev = drv.Device(ordinal) \n",
        "  print(\"Device #%d: %s\" % (ordinal, dev.name())) \n",
        "  print(\"Compute Capability: %d.%d\" % dev.compute_capability())     \n",
        "  print(\"Total Memory: %s KB\" % (dev.total_memory()//(1024)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 device(s) found.\n",
            "Device #0: Tesla K80\n",
            "Compute Capability: 3.7\n",
            "Total Memory: 11715776 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr3XP-FmG6wu"
      },
      "source": [
        "После этого, должно инициализироваться видеоустройство Tesla K80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjwX-DLCH_0p"
      },
      "source": [
        "**How to build a PyCUDA application**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zENbcOgTY0lb"
      },
      "source": [
        "Вычисления могут производиться как на ЦПУ, так и на ГПУ. Как правило, с помощью на ЦПУ происходит подготовка данных, после чего данные передаются на ГПУ для дальнейших трудозатратных вычислений. Обработанные результирующие данные передаются обратно на ЦПУ, для их вывода. Одно из обязательных условий является выделения памяти на ГПУ заранее перед непосредственым выполнением вычислений. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLf-oFmhIDkj",
        "outputId": "b4d93300-3fab-4164-d4ee-505c19624f2b"
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "a = numpy.random.randn(5,5)\n",
        "a = a.astype(numpy.float32)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void doubleMatrix(float *a)\n",
        "{\n",
        "  int idx = threadIdx.x + threadIdx.y*4;\n",
        "a[idx] *= 2; }\n",
        "\"\"\")\n",
        "\n",
        "func = mod.get_function(\"doubleMatrix\")\n",
        "func(a_gpu, block=(5,5,1))\n",
        "\n",
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(\"ORIGINAL MATRIX\")\n",
        "print(a)\n",
        "print(\"DOUBLED MATRIX AFTER PyCUDA EXECUTION\")\n",
        "print(a_doubled)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MATRIX\n",
            "[[ 0.11767171  0.1937645  -1.0480621  -0.38260517 -0.45635247]\n",
            " [-0.30242795  0.6900911   0.76791215 -0.39162463 -0.5633676 ]\n",
            " [-0.91431695  0.48246655 -1.0379905   1.0718129  -1.7166617 ]\n",
            " [ 0.32136446 -1.1683393   0.7952338  -0.7712385   1.5996156 ]\n",
            " [ 0.75574934 -0.9920836   0.05320557  1.942601    2.012559  ]]\n",
            "DOUBLED MATRIX AFTER PyCUDA EXECUTION\n",
            "[[ 0.23534341  0.387529   -2.0961242  -0.76521033 -0.91270494]\n",
            " [-0.6048559   1.3801821   1.5358243  -0.78324926 -1.1267352 ]\n",
            " [-1.8286339   0.9649331  -2.075981    2.1436257  -3.4333234 ]\n",
            " [ 0.6427289  -2.3366785   1.5904676  -1.542477    3.1992311 ]\n",
            " [ 1.5114987  -0.9920836   0.05320557  1.942601    2.012559  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yrnJKbfYQxJ"
      },
      "source": [
        "**Understanding the PyCUDA memory model\n",
        "with matrix manipulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_u70haDigvz"
      },
      "source": [
        "Не вся память одинакова по показателям скорости доступа в модели памяти ГПУ, но лучшей практикой является использование каждого\n",
        "типа памяти наиболее эффективным образом. Основная идея состоит в том, чтобы свести к минимуму  доступ к глобальной памяти (global memory) за счет использования\n",
        "общей памяти(shared memory). \n",
        "\n",
        "Этот метод обычно используется для разделения исходных данных\n",
        "таким образом, чтобы мы позволяли блоку потоков выполнять свои вычисления в закрытом\n",
        "подмножестве данных. Таким образом, потоки, присоединяющиеся к соответствующему блоку память, будут работать вместе, чтобы разгрузить глобальную память, и максимально утилизировать наиболее быстродейственную общую память."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3HEyTqlc9Yp",
        "outputId": "4b41175b-9ddc-43e9-da0c-e598646b79ea"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import pycuda.autoinit\n",
        "\n",
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    float Pvalue = 0;\n",
        "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "        float Aelement = a[ty * %(MATRIX_SIZE)s + k];\n",
        "        float Belement = b[k * %(MATRIX_SIZE)s + tx];\n",
        "        Pvalue += Aelement * Belement;\n",
        "    }\n",
        "\n",
        "    c[ty * %(MATRIX_SIZE)s + tx] = Pvalue;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "MATRIX_SIZE = 5\n",
        "\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu) \n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "kernel_code = kernel_code_template % {\n",
        "    'MATRIX_SIZE': MATRIX_SIZE \n",
        "}\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "matrixmul(\n",
        "    a_gpu, b_gpu, \n",
        "    c_gpu, \n",
        "    block = (MATRIX_SIZE, MATRIX_SIZE, 1),\n",
        ")\n",
        "\n",
        "# print the results\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix A (GPU):\")\n",
        "print(a_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix B (GPU):\")\n",
        "print(b_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix C (GPU):\")\n",
        "print(c_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"CPU-GPU difference:\")\n",
        "print(c_cpu - c_gpu.get())\n",
        "\n",
        "np.allclose(c_cpu, c_gpu.get())\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Matrix A (GPU):\n",
            "[[-1.6566936   0.56398535  1.9507375   0.58440423 -0.7316022 ]\n",
            " [ 1.7494041  -0.5206335   0.5521091  -1.5025228  -0.6369413 ]\n",
            " [ 0.28192496  0.77173406  0.56775284 -0.1784921  -0.35580882]\n",
            " [ 0.7989966   0.2856385  -0.8577809  -2.0350919  -0.24192981]\n",
            " [ 1.4297949   0.6130067  -0.17448708 -0.01680106  0.17822081]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matrix B (GPU):\n",
            "[[ 0.62587035  1.5087065   0.8595771  -0.6473098   0.65500885]\n",
            " [ 1.9399728   2.0890336  -0.5696015   1.1675851  -0.98925865]\n",
            " [ 1.0712496   1.119891    0.35546783 -0.33462828  1.8551363 ]\n",
            " [-0.28716367  1.6689091   0.45135853  1.4509321  -0.7902891 ]\n",
            " [ 0.5076282   0.9004284  -1.5363557  -0.74062985 -0.5335114 ]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matrix C (GPU):\n",
            "[[ 1.6077662   1.1798956   0.33589873  2.4679003   1.9042774 ]\n",
            " [ 0.7844725  -0.9110756   2.2969503  -3.6333623   4.212397  ]\n",
            " [ 2.1524343   2.0550742   0.47065824  0.533129    0.80536604]\n",
            " [ 0.5968958  -2.772685   -0.3276802  -2.670253    0.3868624 ]\n",
            " [ 1.992458    3.3747616   0.5364311  -0.30776727 -0.07539631]]\n",
            "--------------------------------------------------------------------------------\n",
            "CPU-GPU difference:\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAxJYeUSlC2_"
      },
      "source": [
        "**Kernel invocations with GPUArray**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xDTyeESmE3a"
      },
      "source": [
        "В библиотеке PyCUDA представлен класс pycuda.gpuarray.GPUArray который предоставляет высокоуровневый интервейс для выполнения вычислений с помощью CUDA (в отличии от pycuda.compiler.SourceModule, котороый вызывается компилятором nvcc из исходного кода СUDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQ4B5OZlMPp",
        "outputId": "b0c40ad2-a224-4da7-f4fa-4f6a8db01354"
      },
      "source": [
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
        "a_doubled = (2*a_gpu).get()\n",
        "print(\"Doubled matrix using gpuarray call:\\n\", a_doubled)\n",
        "print(\"Original matrix:\\n\",a_gpu)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doubled matrix using gpuarray call:\n",
            " [[-0.76718646 -1.6005294  -1.2835188   1.3084855 ]\n",
            " [-0.7536936   1.927716   -4.4484     -0.49752158]\n",
            " [ 1.0747708  -1.7455909   1.684047    0.23103906]\n",
            " [ 1.2383196   3.658996   -2.9613283   1.3125074 ]]\n",
            "Original matrix:\n",
            " [[-0.38359323 -0.8002647  -0.6417594   0.65424275]\n",
            " [-0.3768468   0.963858   -2.2242     -0.24876079]\n",
            " [ 0.5373854  -0.87279546  0.8420235   0.11551953]\n",
            " [ 0.6191598   1.829498   -1.4806641   0.6562537 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi0pXeBcnIb0"
      },
      "source": [
        "**Evaluating element-wise expressions with\n",
        "PyCUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8JbEBjlqdPx"
      },
      "source": [
        "Функция PyCuda.elementwise.ElementwiseKernel похволяет нам выполнять сложные вычисления которые состоят из одного или более операндов за один вычислительный шаг.\n",
        "\n",
        "В данном примере проводилось вычисления линейной комбинации двух случайно сгенерированных векторов (через pycuda.curandom) с помощью функции ElementwiseKernel. Входными параметрами данной функции стали: список аргументов, используемых для вычисления линейной комбинации 2х векторов, непосредственно определение вычисляемой линейной комбинации, а также наименование данной операции) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QrWUJoSpd5r",
        "outputId": "fc91ab41-32cb-4206-b1a7-484a1f782edd"
      },
      "source": [
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.curandom import rand as curand\n",
        "from pycuda.elementwise import ElementwiseKernel\n",
        "import numpy.linalg as la\n",
        "\n",
        "input_vector_a = curand((50,))\n",
        "input_vector_b = curand((50,))\n",
        "mult_coefficient_a = 2\n",
        "mult_coefficient_b = 5\n",
        "\n",
        "linear_combination = ElementwiseKernel(\n",
        "    \"float a, float *x, float b, float *y, float *c\",\n",
        "    \"c[i] = a*x[i] + b*y[i]\",\n",
        "    \"linear_combination\")\n",
        "\n",
        "linear_combination_result = gpuarray.empty_like(input_vector_a)\n",
        "linear_combination(mult_coefficient_a,\n",
        "                   input_vector_a,\\\n",
        "                   mult_coefficient_b, input_vector_b,\\\n",
        "                   linear_combination_result)\n",
        "\n",
        "print(\"INPUT VECTOR A =\")\n",
        "print(input_vector_a)\n",
        "\n",
        "print(\"INPUT VECTOR B = \")\n",
        "print(input_vector_b)\n",
        "\n",
        "print(\"RESULTING VECTOR C = \")\n",
        "print(linear_combination_result)\n",
        "\n",
        "print(\"CHECKING THE RESULT EVALUATING THE DIFFERENCE VECTOR BETWEEN CAND THE LINEAR COMBINATION OF A AND B\")\n",
        "print(\"C - (%sA + %sB) = \"%(mult_coefficient_a,mult_coefficient_b))\n",
        "\n",
        "print(linear_combination_result -\n",
        "      (mult_coefficient_a * input_vector_a + mult_coefficient_b * input_vector_b))\n",
        "\n",
        "assert la.norm((linear_combination_result - \\\n",
        "                (mult_coefficient_a*input_vector_a +\\\n",
        "                 mult_coefficient_b*input_vector_b)).get()) < 1e-5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n",
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT VECTOR A =\n",
            "[0.16397922 0.2542899  0.1561198  0.7423383  0.48986718 0.24225038\n",
            " 0.5527745  0.928087   0.9870533  0.42109317 0.32900068 0.32025725\n",
            " 0.1596376  0.41115913 0.10089948 0.5432142  0.616877   0.17013712\n",
            " 0.10183815 0.24852332 0.6760686  0.98465866 0.29470316 0.45642775\n",
            " 0.24516201 0.5604631  0.6643754  0.07468423 0.7439757  0.315316\n",
            " 0.40665123 0.52793115 0.7565336  0.20500064 0.2343749  0.8014761\n",
            " 0.2337355  0.13296954 0.64089704 0.31119043 0.98951477 0.74160135\n",
            " 0.8360364  0.56541276 0.6560929  0.8817107  0.01718229 0.5732893\n",
            " 0.45194414 0.713942  ]\n",
            "INPUT VECTOR B = \n",
            "[0.79965776 0.43139103 0.15423283 0.66269946 0.96225375 0.48722842\n",
            " 0.05734671 0.46749467 0.3964474  0.276251   0.94695324 0.04347985\n",
            " 0.99261177 0.60987836 0.28042185 0.8317375  0.19229913 0.6702712\n",
            " 0.38508534 0.8897452  0.08817302 0.12089943 0.62499756 0.9237239\n",
            " 0.187887   0.96184856 0.6624714  0.19917026 0.38990816 0.35291624\n",
            " 0.21171579 0.36110634 0.4578505  0.6894811  0.63080394 0.80449146\n",
            " 0.83014184 0.52584934 0.37348917 0.33291838 0.7680599  0.30139637\n",
            " 0.00656578 0.7368209  0.6494745  0.8924528  0.8785763  0.6442794\n",
            " 0.8975784  0.4001976 ]\n",
            "RESULTING VECTOR C = \n",
            "[4.326247   2.665535   1.0834038  4.798174   5.791003   2.9206429\n",
            " 1.3922825  4.1936474  3.9563437  2.2234411  5.3927674  0.85791373\n",
            " 5.2823343  3.87171    1.6039082  5.245116   2.1952496  3.6916304\n",
            " 2.129103   4.945772   1.7930024  2.5738144  3.714394   5.531475\n",
            " 1.429759   5.930169   4.6411076  1.1452198  3.4374924  2.3952131\n",
            " 1.8718815  2.861394   3.8023198  3.8574066  3.6227696  5.625409\n",
            " 4.6181803  2.8951857  3.14924    2.2869728  5.8193293  2.9901845\n",
            " 1.7049017  4.81493    4.5595584  6.2256856  4.427246   4.3679757\n",
            " 5.3917804  3.428872  ]\n",
            "CHECKING THE RESULT EVALUATING THE DIFFERENCE VECTOR BETWEEN CAND THE LINEAR COMBINATION OF A AND B\n",
            "C - (2A + 5B) = \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cy1z25AsI7B"
      },
      "source": [
        "**The MapReduce operation with PyCUDA**"
      ]
    }
  ]
}
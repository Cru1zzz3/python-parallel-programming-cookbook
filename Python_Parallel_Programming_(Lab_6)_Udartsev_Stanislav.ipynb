{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Python Parallel Programming (Lab 6) - Udartsev Stanislav.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPhuRlRSpWVD1b4lkcHN1G+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Cru1zzz3/python-parallel-programming-cookbook/blob/main/Python_Parallel_Programming_(Lab_6)_Udartsev_Stanislav.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6IBhYGq5vYP"
      },
      "source": [
        "Проверяем версию компилятора NVIDIA CUDA"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "avsaG-Oi5JoQ",
        "outputId": "6e877e73-85af-4ccd-8c5c-74efd6a1639c"
      },
      "source": [
        "!nvcc --version "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2020 NVIDIA Corporation\n",
            "Built on Mon_Oct_12_20:09:46_PDT_2020\n",
            "Cuda compilation tools, release 11.1, V11.1.105\n",
            "Build cuda_11.1.TC455_06.29190527_0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fydH8jO5Yxh",
        "outputId": "5ce8a335-4a6e-4c89-b4df-ca2021441b9e"
      },
      "source": [
        "!pip install pycuda"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pycuda\n",
            "  Downloading pycuda-2021.1.tar.gz (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 5.3 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pytools>=2011.2\n",
            "  Downloading pytools-2021.2.9.tar.gz (66 kB)\n",
            "\u001b[K     |████████████████████████████████| 66 kB 4.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pycuda) (1.4.4)\n",
            "Collecting mako\n",
            "  Downloading Mako-1.1.6-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from pytools>=2011.2->pycuda) (1.19.5)\n",
            "Requirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.7/dist-packages (from mako->pycuda) (2.0.1)\n",
            "Building wheels for collected packages: pycuda, pytools\n",
            "  Building wheel for pycuda (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pycuda: filename=pycuda-2021.1-cp37-cp37m-linux_x86_64.whl size=627577 sha256=ec22c1730cd95b1da08eb219c6dd479987fa85bd288091e572215c4f57efe8d1\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/ef/49/dc6a5feb8d980b37c83d465ecab24949a6aa19458522a9e001\n",
            "  Building wheel for pytools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pytools: filename=pytools-2021.2.9-py2.py3-none-any.whl size=62370 sha256=fd43ca6700e7be573940ce4d29453a8435e581538bfb1286b13e28761af07b50\n",
            "  Stored in directory: /root/.cache/pip/wheels/41/b9/6e/94bb014f6484b15ec77e7877f3a227609481ffd98db364504d\n",
            "Successfully built pycuda pytools\n",
            "Installing collected packages: pytools, mako, pycuda\n",
            "Successfully installed mako-1.1.6 pycuda-2021.1 pytools-2021.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mEGY9XPQx0jv"
      },
      "source": [
        "**Using the PyCUDA module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YrYwwivT_-oE"
      },
      "source": [
        "Для того, чтобы инициализировать CUDA драйвер, необходимо сменить тип Runtime'a в Google Collab на тот, который поддерживает аппаратное ускорение GPU. \n",
        "Для этого необходимо: \n",
        "\n",
        "*   Нажать на вкладку `Runtime` и выбрать `Change runtime type`.\n",
        "*   После этого в разделе `Hardware Acceleration`, выбрать `GPU` и нажать `Save`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMUqConq5lrh",
        "outputId": "eec264d9-4bc8-4928-84a4-42d6e589cdcf"
      },
      "source": [
        "import pycuda.driver as drv \n",
        "drv.init() \n",
        "print(\"%d device(s) found.\" % drv.Device.count()) \n",
        "for ordinal in range(drv.Device.count()): \n",
        "  dev = drv.Device(ordinal) \n",
        "  print(\"Device #%d: %s\" % (ordinal, dev.name())) \n",
        "  print(\"Compute Capability: %d.%d\" % dev.compute_capability())     \n",
        "  print(\"Total Memory: %s KB\" % (dev.total_memory()//(1024)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 device(s) found.\n",
            "Device #0: Tesla K80\n",
            "Compute Capability: 3.7\n",
            "Total Memory: 11715776 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cr3XP-FmG6wu"
      },
      "source": [
        "После этого, должно инициализироваться видеоустройство Tesla K80"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mjwX-DLCH_0p"
      },
      "source": [
        "**How to build a PyCUDA application**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zENbcOgTY0lb"
      },
      "source": [
        "Вычисления могут производиться как на ЦПУ, так и на ГПУ. Как правило, с помощью на ЦПУ происходит подготовка данных, после чего данные передаются на ГПУ для дальнейших трудозатратных вычислений. Обработанные результирующие данные передаются обратно на ЦПУ, для их вывода. Одно из обязательных условий является выделения памяти на ГПУ заранее перед непосредственым выполнением вычислений. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLf-oFmhIDkj",
        "outputId": "b4d93300-3fab-4164-d4ee-505c19624f2b"
      },
      "source": [
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import numpy\n",
        "\n",
        "a = numpy.random.randn(5,5)\n",
        "a = a.astype(numpy.float32)\n",
        "\n",
        "a_gpu = cuda.mem_alloc(a.nbytes)\n",
        "cuda.memcpy_htod(a_gpu, a)\n",
        "\n",
        "mod = SourceModule(\"\"\"\n",
        "__global__ void doubleMatrix(float *a)\n",
        "{\n",
        "  int idx = threadIdx.x + threadIdx.y*4;\n",
        "a[idx] *= 2; }\n",
        "\"\"\")\n",
        "\n",
        "func = mod.get_function(\"doubleMatrix\")\n",
        "func(a_gpu, block=(5,5,1))\n",
        "\n",
        "a_doubled = numpy.empty_like(a)\n",
        "cuda.memcpy_dtoh(a_doubled, a_gpu)\n",
        "print(\"ORIGINAL MATRIX\")\n",
        "print(a)\n",
        "print(\"DOUBLED MATRIX AFTER PyCUDA EXECUTION\")\n",
        "print(a_doubled)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL MATRIX\n",
            "[[ 0.11767171  0.1937645  -1.0480621  -0.38260517 -0.45635247]\n",
            " [-0.30242795  0.6900911   0.76791215 -0.39162463 -0.5633676 ]\n",
            " [-0.91431695  0.48246655 -1.0379905   1.0718129  -1.7166617 ]\n",
            " [ 0.32136446 -1.1683393   0.7952338  -0.7712385   1.5996156 ]\n",
            " [ 0.75574934 -0.9920836   0.05320557  1.942601    2.012559  ]]\n",
            "DOUBLED MATRIX AFTER PyCUDA EXECUTION\n",
            "[[ 0.23534341  0.387529   -2.0961242  -0.76521033 -0.91270494]\n",
            " [-0.6048559   1.3801821   1.5358243  -0.78324926 -1.1267352 ]\n",
            " [-1.8286339   0.9649331  -2.075981    2.1436257  -3.4333234 ]\n",
            " [ 0.6427289  -2.3366785   1.5904676  -1.542477    3.1992311 ]\n",
            " [ 1.5114987  -0.9920836   0.05320557  1.942601    2.012559  ]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7yrnJKbfYQxJ"
      },
      "source": [
        "**Understanding the PyCUDA memory model\n",
        "with matrix manipulation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_u70haDigvz"
      },
      "source": [
        "Не вся память одинакова по показателям скорости доступа в модели памяти ГПУ, но лучшей практикой является использование каждого\n",
        "типа памяти наиболее эффективным образом. Основная идея состоит в том, чтобы свести к минимуму  доступ к глобальной памяти (global memory) за счет использования\n",
        "общей памяти(shared memory). \n",
        "\n",
        "Этот метод обычно используется для разделения исходных данных\n",
        "таким образом, чтобы мы позволяли блоку потоков выполнять свои вычисления в закрытом\n",
        "подмножестве данных. Таким образом, потоки, присоединяющиеся к соответствующему блоку память, будут работать вместе, чтобы разгрузить глобальную память, и максимально утилизировать наиболее быстродейственную общую память."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3HEyTqlc9Yp",
        "outputId": "4b41175b-9ddc-43e9-da0c-e598646b79ea"
      },
      "source": [
        "\n",
        "import numpy as np\n",
        "from pycuda import driver, compiler, gpuarray, tools\n",
        "from pycuda.compiler import SourceModule\n",
        "\n",
        "import pycuda.autoinit\n",
        "\n",
        "kernel_code_template = \"\"\"\n",
        "__global__ void MatrixMulKernel(float *a, float *b, float *c)\n",
        "{\n",
        "    int tx = threadIdx.x;\n",
        "    int ty = threadIdx.y;\n",
        "    float Pvalue = 0;\n",
        "    for (int k = 0; k < %(MATRIX_SIZE)s; ++k) {\n",
        "        float Aelement = a[ty * %(MATRIX_SIZE)s + k];\n",
        "        float Belement = b[k * %(MATRIX_SIZE)s + tx];\n",
        "        Pvalue += Aelement * Belement;\n",
        "    }\n",
        "\n",
        "    c[ty * %(MATRIX_SIZE)s + tx] = Pvalue;\n",
        "}\n",
        "\"\"\"\n",
        "\n",
        "MATRIX_SIZE = 5\n",
        "\n",
        "a_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "b_cpu = np.random.randn(MATRIX_SIZE, MATRIX_SIZE).astype(np.float32)\n",
        "\n",
        "c_cpu = np.dot(a_cpu, b_cpu)\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(a_cpu) \n",
        "b_gpu = gpuarray.to_gpu(b_cpu)\n",
        "\n",
        "c_gpu = gpuarray.empty((MATRIX_SIZE, MATRIX_SIZE), np.float32)\n",
        "\n",
        "kernel_code = kernel_code_template % {\n",
        "    'MATRIX_SIZE': MATRIX_SIZE \n",
        "}\n",
        "\n",
        "mod = compiler.SourceModule(kernel_code)\n",
        "\n",
        "matrixmul = mod.get_function(\"MatrixMulKernel\")\n",
        "\n",
        "matrixmul(\n",
        "    a_gpu, b_gpu, \n",
        "    c_gpu, \n",
        "    block = (MATRIX_SIZE, MATRIX_SIZE, 1),\n",
        ")\n",
        "\n",
        "# print the results\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix A (GPU):\")\n",
        "print(a_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix B (GPU):\")\n",
        "print(b_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"Matrix C (GPU):\")\n",
        "print(c_gpu.get())\n",
        "\n",
        "print(\"-\" * 80)\n",
        "print(\"CPU-GPU difference:\")\n",
        "print(c_cpu - c_gpu.get())\n",
        "\n",
        "np.allclose(c_cpu, c_gpu.get())\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "Matrix A (GPU):\n",
            "[[-1.6566936   0.56398535  1.9507375   0.58440423 -0.7316022 ]\n",
            " [ 1.7494041  -0.5206335   0.5521091  -1.5025228  -0.6369413 ]\n",
            " [ 0.28192496  0.77173406  0.56775284 -0.1784921  -0.35580882]\n",
            " [ 0.7989966   0.2856385  -0.8577809  -2.0350919  -0.24192981]\n",
            " [ 1.4297949   0.6130067  -0.17448708 -0.01680106  0.17822081]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matrix B (GPU):\n",
            "[[ 0.62587035  1.5087065   0.8595771  -0.6473098   0.65500885]\n",
            " [ 1.9399728   2.0890336  -0.5696015   1.1675851  -0.98925865]\n",
            " [ 1.0712496   1.119891    0.35546783 -0.33462828  1.8551363 ]\n",
            " [-0.28716367  1.6689091   0.45135853  1.4509321  -0.7902891 ]\n",
            " [ 0.5076282   0.9004284  -1.5363557  -0.74062985 -0.5335114 ]]\n",
            "--------------------------------------------------------------------------------\n",
            "Matrix C (GPU):\n",
            "[[ 1.6077662   1.1798956   0.33589873  2.4679003   1.9042774 ]\n",
            " [ 0.7844725  -0.9110756   2.2969503  -3.6333623   4.212397  ]\n",
            " [ 2.1524343   2.0550742   0.47065824  0.533129    0.80536604]\n",
            " [ 0.5968958  -2.772685   -0.3276802  -2.670253    0.3868624 ]\n",
            " [ 1.992458    3.3747616   0.5364311  -0.30776727 -0.07539631]]\n",
            "--------------------------------------------------------------------------------\n",
            "CPU-GPU difference:\n",
            "[[0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0.]]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAxJYeUSlC2_"
      },
      "source": [
        "**Kernel invocations with GPUArray**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9xDTyeESmE3a"
      },
      "source": [
        "В библиотеке PyCUDA представлен класс pycuda.gpuarray.GPUArray который предоставляет высокоуровневый интервейс для выполнения вычислений с помощью CUDA (в отличии от pycuda.compiler.SourceModule, котороый вызывается компилятором nvcc из исходного кода СUDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AwQ4B5OZlMPp",
        "outputId": "b0c40ad2-a224-4da7-f4fa-4f6a8db01354"
      },
      "source": [
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.driver as cuda\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "\n",
        "a_gpu = gpuarray.to_gpu(numpy.random.randn(4,4).astype(numpy.float32))\n",
        "a_doubled = (2*a_gpu).get()\n",
        "print(\"Doubled matrix using gpuarray call:\\n\", a_doubled)\n",
        "print(\"Original matrix:\\n\",a_gpu)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Doubled matrix using gpuarray call:\n",
            " [[-0.76718646 -1.6005294  -1.2835188   1.3084855 ]\n",
            " [-0.7536936   1.927716   -4.4484     -0.49752158]\n",
            " [ 1.0747708  -1.7455909   1.684047    0.23103906]\n",
            " [ 1.2383196   3.658996   -2.9613283   1.3125074 ]]\n",
            "Original matrix:\n",
            " [[-0.38359323 -0.8002647  -0.6417594   0.65424275]\n",
            " [-0.3768468   0.963858   -2.2242     -0.24876079]\n",
            " [ 0.5373854  -0.87279546  0.8420235   0.11551953]\n",
            " [ 0.6191598   1.829498   -1.4806641   0.6562537 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi0pXeBcnIb0"
      },
      "source": [
        "**Evaluating element-wise expressions with\n",
        "PyCUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8JbEBjlqdPx"
      },
      "source": [
        "Функция PyCuda.elementwise.ElementwiseKernel похволяет нам выполнять сложные вычисления которые состоят из одного или более операндов за один вычислительный шаг.\n",
        "\n",
        "В данном примере проводилось вычисления линейной комбинации двух случайно сгенерированных векторов (через pycuda.curandom) с помощью функции ElementwiseKernel. Входными параметрами данной функции стали: список аргументов, используемых для вычисления линейной комбинации 2х векторов, непосредственно определение вычисляемой линейной комбинации, а также наименование данной операции) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QrWUJoSpd5r",
        "outputId": "fc91ab41-32cb-4206-b1a7-484a1f782edd"
      },
      "source": [
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.curandom import rand as curand\n",
        "from pycuda.elementwise import ElementwiseKernel\n",
        "import numpy.linalg as la\n",
        "\n",
        "input_vector_a = curand((50,))\n",
        "input_vector_b = curand((50,))\n",
        "mult_coefficient_a = 2\n",
        "mult_coefficient_b = 5\n",
        "\n",
        "linear_combination = ElementwiseKernel(\n",
        "    \"float a, float *x, float b, float *y, float *c\",\n",
        "    \"c[i] = a*x[i] + b*y[i]\",\n",
        "    \"linear_combination\")\n",
        "\n",
        "linear_combination_result = gpuarray.empty_like(input_vector_a)\n",
        "linear_combination(mult_coefficient_a,\n",
        "                   input_vector_a,\\\n",
        "                   mult_coefficient_b, input_vector_b,\\\n",
        "                   linear_combination_result)\n",
        "\n",
        "print(\"INPUT VECTOR A =\")\n",
        "print(input_vector_a)\n",
        "\n",
        "print(\"INPUT VECTOR B = \")\n",
        "print(input_vector_b)\n",
        "\n",
        "print(\"RESULTING VECTOR C = \")\n",
        "print(linear_combination_result)\n",
        "\n",
        "print(\"CHECKING THE RESULT EVALUATING THE DIFFERENCE VECTOR BETWEEN CAND THE LINEAR COMBINATION OF A AND B\")\n",
        "print(\"C - (%sA + %sB) = \"%(mult_coefficient_a,mult_coefficient_b))\n",
        "\n",
        "print(linear_combination_result -\n",
        "      (mult_coefficient_a * input_vector_a + mult_coefficient_b * input_vector_b))\n",
        "\n",
        "assert la.norm((linear_combination_result - \\\n",
        "                (mult_coefficient_a*input_vector_a +\\\n",
        "                 mult_coefficient_b*input_vector_b)).get()) < 1e-5"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n",
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT VECTOR A =\n",
            "[0.16397922 0.2542899  0.1561198  0.7423383  0.48986718 0.24225038\n",
            " 0.5527745  0.928087   0.9870533  0.42109317 0.32900068 0.32025725\n",
            " 0.1596376  0.41115913 0.10089948 0.5432142  0.616877   0.17013712\n",
            " 0.10183815 0.24852332 0.6760686  0.98465866 0.29470316 0.45642775\n",
            " 0.24516201 0.5604631  0.6643754  0.07468423 0.7439757  0.315316\n",
            " 0.40665123 0.52793115 0.7565336  0.20500064 0.2343749  0.8014761\n",
            " 0.2337355  0.13296954 0.64089704 0.31119043 0.98951477 0.74160135\n",
            " 0.8360364  0.56541276 0.6560929  0.8817107  0.01718229 0.5732893\n",
            " 0.45194414 0.713942  ]\n",
            "INPUT VECTOR B = \n",
            "[0.79965776 0.43139103 0.15423283 0.66269946 0.96225375 0.48722842\n",
            " 0.05734671 0.46749467 0.3964474  0.276251   0.94695324 0.04347985\n",
            " 0.99261177 0.60987836 0.28042185 0.8317375  0.19229913 0.6702712\n",
            " 0.38508534 0.8897452  0.08817302 0.12089943 0.62499756 0.9237239\n",
            " 0.187887   0.96184856 0.6624714  0.19917026 0.38990816 0.35291624\n",
            " 0.21171579 0.36110634 0.4578505  0.6894811  0.63080394 0.80449146\n",
            " 0.83014184 0.52584934 0.37348917 0.33291838 0.7680599  0.30139637\n",
            " 0.00656578 0.7368209  0.6494745  0.8924528  0.8785763  0.6442794\n",
            " 0.8975784  0.4001976 ]\n",
            "RESULTING VECTOR C = \n",
            "[4.326247   2.665535   1.0834038  4.798174   5.791003   2.9206429\n",
            " 1.3922825  4.1936474  3.9563437  2.2234411  5.3927674  0.85791373\n",
            " 5.2823343  3.87171    1.6039082  5.245116   2.1952496  3.6916304\n",
            " 2.129103   4.945772   1.7930024  2.5738144  3.714394   5.531475\n",
            " 1.429759   5.930169   4.6411076  1.1452198  3.4374924  2.3952131\n",
            " 1.8718815  2.861394   3.8023198  3.8574066  3.6227696  5.625409\n",
            " 4.6181803  2.8951857  3.14924    2.2869728  5.8193293  2.9901845\n",
            " 1.7049017  4.81493    4.5595584  6.2256856  4.427246   4.3679757\n",
            " 5.3917804  3.428872  ]\n",
            "CHECKING THE RESULT EVALUATING THE DIFFERENCE VECTOR BETWEEN CAND THE LINEAR COMBINATION OF A AND B\n",
            "C - (2A + 5B) = \n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Cy1z25AsI7B"
      },
      "source": [
        "**The MapReduce operation with PyCUDA**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9fBO_R6s_q4"
      },
      "source": [
        "PyCUDA предоставляет возможность выполнения операций методом MapReduce на ГПУ. Это возможно\n",
        "с помощью встроенного в библиотеку метода pycuda.reduction.ReductionKernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwg0WSdislPL",
        "outputId": "29aa113c-b360-4ad6-d0e3-a0c6da8b1ed1"
      },
      "source": [
        "import pycuda.gpuarray as gpuarray\n",
        "import pycuda.autoinit\n",
        "import numpy\n",
        "from pycuda.reduction import ReductionKernel\n",
        "\n",
        "vector_length = 400\n",
        "input_vector_a = gpuarray.arange(vector_length, dtype=numpy.int)\n",
        "input_vector_b = gpuarray.arange(vector_length, dtype=numpy.int)\n",
        "dot_product = ReductionKernel(numpy.int,\n",
        "                              arguments=\"int *x, int *y\",\n",
        "                              map_expr=\"x[i]*y[i]\",\n",
        "                              reduce_expr=\"a+b\", neutral=\"0\")\n",
        "\n",
        "dot_product = dot_product (input_vector_a, input_vector_b).get()\n",
        "\n",
        "print(\"INPUT VECTOR A\")\n",
        "print(input_vector_a)\n",
        "\n",
        "print(\"INPUT VECTOR B\")\n",
        "print(input_vector_b)\n",
        "\n",
        "print(\"RESULT DOT PRODUCT OF A * B\")\n",
        "print(dot_product)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/elementwise.py:82: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  no_extern_c=True,\n",
            "/usr/local/lib/python3.7/dist-packages/pycuda/reduction.py:157: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  return SourceModule(src, options=options, keep=keep, no_extern_c=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT VECTOR A\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399]\n",
            "INPUT VECTOR B\n",
            "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
            "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
            "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
            "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
            "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
            "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
            " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
            " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
            " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
            " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
            " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
            " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
            " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
            " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
            " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
            " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
            " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
            " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
            " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
            " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
            " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
            " 396 397 398 399]\n",
            "RESULT DOT PRODUCT OF A * B\n",
            "2646700\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pycuda/reduction.py:157: UserWarning: The CUDA compiler succeeded, but said the following:\n",
            "nvcc warning : The 'compute_35', 'compute_37', 'compute_50', 'sm_35', 'sm_37' and 'sm_50' architectures are deprecated, and may be removed in a future release (Use -Wno-deprecated-gpu-targets to suppress warning).\n",
            "\n",
            "  return SourceModule(src, options=options, keep=keep, no_extern_c=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSg0nhJctgKD"
      },
      "source": [
        "**GPU programming with NumbaPro**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPByBx2Vtm5Q"
      },
      "source": [
        "Numba - это компилятор Python, который предоставляет API на основе CUDA для написания программ CUDA.\n",
        "Он предназначен для вычислительных задач, ориентированных на использование массивов данных, так же, как и широко используемая библиотека NumPy.\n",
        "Параллелизм данных в задачах, ориентированных на массивы данных, естественным образом подходит для ускорителей, таких\n",
        "как графические процессоры. NumbaPro понимает типы массивов NumPy и использует их для создания эффективного\n",
        "скомпилированного кода для выполнения на графических процессорах или многоядерных процессорах."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJBvwog0wCNV"
      },
      "source": [
        "В данном примере с помощью декоратора @guvectorize библиотеки numba мы определяем тип входных данных, а также каким образом манипулируем размерностями обрабатываемых матриц при умножении с помощью функции matmul()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FBkmsivZt3L_",
        "outputId": "e25f0ef8-1b49-4031-cb5b-2c7dd98887cc"
      },
      "source": [
        "from numba import guvectorize\n",
        "import numpy as np\n",
        "\n",
        "@guvectorize(['void(int64[:,:], int64[:,:], int64[:,:])'],\n",
        "             '(m,n),(n,p)->(m,p)')\n",
        "def matmul(A, B, C):\n",
        "    m, n = A.shape\n",
        "    n, p = B.shape\n",
        "    for i in range(m):\n",
        "        for j in range(p):\n",
        "            C[i, j] = 0\n",
        "            for k in range(n):\n",
        "                C[i, j] += A[i, k] * B[k, j]\n",
        "\n",
        "dim = 10\n",
        "A = np.random.randint(dim,size=(dim, dim))\n",
        "B = np.random.randint(dim,size=(dim, dim))\n",
        "\n",
        "C = matmul(A, B)\n",
        "print(\"INPUT MATRIX A\")\n",
        "print(\":\\n%s\" % A)\n",
        "print(\"INPUT MATRIX B\")\n",
        "print(\":\\n%s\" % B)\n",
        "print(\"RESULT MATRIX C = A*B\")\n",
        "print(\":\\n%s\" % C)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INPUT MATRIX A\n",
            ":\n",
            "[[7 3 9 6 2 6 9 4 6 8]\n",
            " [5 6 0 9 5 1 8 9 4 3]\n",
            " [5 3 8 4 3 1 7 7 1 9]\n",
            " [0 1 6 0 8 1 7 5 7 7]\n",
            " [5 5 0 3 3 7 4 3 1 8]\n",
            " [2 0 5 6 9 4 1 6 7 0]\n",
            " [6 1 0 8 8 8 0 3 2 2]\n",
            " [0 5 9 5 8 5 8 2 3 2]\n",
            " [0 1 4 4 6 7 2 9 4 1]\n",
            " [6 0 1 7 5 2 3 5 9 1]]\n",
            "INPUT MATRIX B\n",
            ":\n",
            "[[6 6 6 5 9 8 3 7 8 4]\n",
            " [9 5 6 6 7 5 7 0 2 6]\n",
            " [4 4 2 1 4 6 1 4 1 5]\n",
            " [2 8 0 3 5 6 0 0 9 9]\n",
            " [5 7 3 4 3 3 3 2 1 4]\n",
            " [3 3 4 1 3 3 6 8 2 7]\n",
            " [7 3 3 7 8 2 4 1 5 6]\n",
            " [4 5 8 1 7 6 8 8 0 6]\n",
            " [5 2 5 9 9 1 7 5 0 0]\n",
            " [3 2 6 5 4 5 6 1 6 6]]\n",
            "RESULT MATRIX C = A*B\n",
            ":\n",
            "[[278 248 245 255 360 273 251 216 232 321]\n",
            " [251 253 219 225 325 231 228 156 198 284]\n",
            " [224 209 213 186 280 241 204 158 184 271]\n",
            " [201 162 184 197 240 154 202 137  95 189]\n",
            " [186 166 186 163 219 180 196 138 162 228]\n",
            " [167 202 151 149 220 166 163 168  97 193]\n",
            " [153 208 144 131 196 179 147 158 158 220]\n",
            " [231 216 159 186 248 189 179 133 134 259]\n",
            " [157 177 164 117 201 159 185 179  78 207]\n",
            " [174 191 161 186 258 167 167 161 142 180]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-7YMHO2w9NQ"
      },
      "source": [
        "**Using GPU-accelerated libraries with\n",
        "NumbaPro**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ENQ_efPxn-Z"
      },
      "source": [
        "NumbaPro предоставляет оболочку Python для библиотек CUDA для численных вычислений. Каждый код,\n",
        "использующий эти библиотеки, значительно ускорится без написания какого-либо дополнительного кода, специфичного для графического процессора.\n",
        "Библиотека cuBLAS - предоставляет основные функции\n",
        "линейной алгебры для работы на графическом процессоре, такие как операции над векторами, операции над матрицами и векторами, операциями над матрицами."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRpp_-EYxR_x"
      },
      "source": [
        "В данном примере представлена реализация алгоритма общего умножения матриц (GEMM), который представляет\n",
        "собой процедуру для выполнения умножения матриц на графических процессорах NVIDIA:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLako1nFw8yi",
        "outputId": "687ed3d5-2402-4289-d5cc-d1ef0f85908e"
      },
      "source": [
        "import cupy\n",
        "from cupy import cublas\n",
        "import numpy as np\n",
        "from timeit import default_timer as timer\n",
        "\n",
        "dim = 10\n",
        "\n",
        "def gemm():\n",
        "  A = cupy.random.rand(dim, dim)\n",
        "  B = cupy.random.rand(dim, dim)\n",
        "  D = cupy.zeros_like(A, order='F')\n",
        "\n",
        "  print(\"MATRIX A :\")\n",
        "  print(A)\n",
        "  print(\"VECTOR B :\")\n",
        "  print(B)\n",
        "\n",
        "  # NumPy\n",
        "  start = timer()\n",
        "  E = np.dot(A, B)\n",
        "  numpy_time = timer() - start\n",
        "  print(\"Numpy took %f seconds\" % numpy_time)\n",
        "\n",
        "  # cuBLAS\n",
        "  start = timer()\n",
        "  cublas.gemm('T', 'T', A, B, D, 1.0, 1.0)\n",
        "  cuda_time = timer() - start\n",
        "\n",
        "  print(\"RESULT MATRIX EVALUATED WITH CUBLAS\")\n",
        "  print(D)\n",
        "  print(\"CUBLAS took %f seconds\" % cuda_time)\n",
        "\n",
        "  diff = np.abs(D - E)\n",
        "  print(\"Maximum error %f\" % np.max(diff))\n",
        "\n",
        "def main():\n",
        "  gemm()\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MATRIX A :\n",
            "[[0.10516194 0.55898318 0.62423573 0.21454811 0.88163658 0.68769649\n",
            "  0.03899582 0.04067878 0.95279899 0.91470366]\n",
            " [0.59185705 0.12804578 0.89171253 0.35070279 0.01588767 0.75925402\n",
            "  0.4226423  0.70868928 0.81258481 0.91337733]\n",
            " [0.70762026 0.24504798 0.20095707 0.53097925 0.77899371 0.10325536\n",
            "  0.03842074 0.13368743 0.18296487 0.01186485]\n",
            " [0.32862373 0.53784013 0.94339876 0.4308364  0.17901376 0.00720555\n",
            "  0.46994049 0.05660561 0.44849926 0.64717449]\n",
            " [0.2116461  0.78991917 0.81404575 0.322688   0.27266099 0.26849148\n",
            "  0.56910238 0.96720697 0.00413226 0.5414472 ]\n",
            " [0.77945543 0.94755332 0.80392584 0.47441502 0.42985723 0.25004376\n",
            "  0.71482539 0.05051171 0.87460246 0.70154276]\n",
            " [0.31990863 0.28220787 0.61881977 0.55184627 0.27329084 0.29894347\n",
            "  0.08852946 0.83088912 0.46035398 0.04905428]\n",
            " [0.9393886  0.16564115 0.68263068 0.76415421 0.62502278 0.00125616\n",
            "  0.71406214 0.41892215 0.57294203 0.27713827]\n",
            " [0.17708274 0.24297934 0.6190124  0.82863371 0.636678   0.36127385\n",
            "  0.95003108 0.90634607 0.57055561 0.72115887]\n",
            " [0.44539204 0.36391422 0.42176651 0.05647624 0.22293305 0.50951183\n",
            "  0.04097957 0.23516103 0.68486114 0.19034112]]\n",
            "VECTOR B :\n",
            "[[0.87981821 0.67459351 0.00271352 0.65240547 0.10412983 0.21916026\n",
            "  0.87657569 0.17880863 0.91190585 0.73333821]\n",
            " [0.45001015 0.41384792 0.30005558 0.37966381 0.0433424  0.99006775\n",
            "  0.28916885 0.67249732 0.37962683 0.6739578 ]\n",
            " [0.16986786 0.23032289 0.4411518  0.78886594 0.19470509 0.92036948\n",
            "  0.48531196 0.63602501 0.50966242 0.50301449]\n",
            " [0.85726555 0.30760821 0.72014353 0.82928108 0.05929628 0.41712466\n",
            "  0.84499438 0.64663336 0.6225759  0.32664713]\n",
            " [0.91218983 0.17060794 0.24773787 0.87821269 0.43707813 0.86419404\n",
            "  0.37631723 0.0106212  0.01311098 0.23550771]\n",
            " [0.2207283  0.99011533 0.91734306 0.81533422 0.22741811 0.22681144\n",
            "  0.03360017 0.77142959 0.20603055 0.54259631]\n",
            " [0.24648078 0.11929379 0.8418396  0.71752967 0.55836493 0.87647335\n",
            "  0.28608398 0.22512321 0.57928346 0.50200316]\n",
            " [0.3637856  0.62974186 0.76098447 0.93582505 0.31953713 0.562842\n",
            "  0.18486561 0.1400679  0.25539156 0.95861074]\n",
            " [0.84392096 0.55810072 0.35246017 0.97417435 0.71975612 0.17080996\n",
            "  0.52888511 0.5550126  0.75053841 0.49293918]\n",
            " [0.85943396 0.50279423 0.30032356 0.8722866  0.77477458 0.51049708\n",
            "  0.22253585 0.68970722 0.92617019 0.20466665]]\n",
            "Numpy took 0.000165 seconds\n",
            "RESULT MATRIX EVALUATED WITH CUBLAS\n",
            "[[1.83746741 2.50188635 2.55120664 2.52549579 1.66449521 2.7647829\n",
            "  2.3585412  2.42623627 2.31710731 2.4232788 ]\n",
            " [1.98509849 2.08514826 2.23193503 2.19888021 2.4257657  1.69281627\n",
            "  2.45829423 2.24579758 2.48686184 2.65983331]\n",
            " [3.56601744 3.05689943 3.3048276  3.60756374 2.99796169 3.24546328\n",
            "  3.16650445 3.30943273 4.11621921 4.17736454]\n",
            " [2.26286487 2.0743744  2.39537103 2.74326368 1.55642773 2.22334764\n",
            "  2.28511397 1.95110335 2.66267866 2.81706049]\n",
            " [2.12329606 2.03373337 2.05380015 2.76988631 1.81811557 1.97387932\n",
            "  2.23206135 1.93450242 2.5507054  2.71368866]\n",
            " [2.17033791 1.48443009 1.21163525 1.66841415 1.3594324  1.48381754\n",
            "  1.27210807 1.67628524 1.9645851  1.85201374]\n",
            " [1.94371287 2.00887837 2.26228261 2.05413178 1.45939995 1.90882449\n",
            "  2.13085087 1.73184105 2.44821698 2.87379264]\n",
            " [2.4651439  1.48968447 1.75848295 2.08857828 1.0916356  1.77628926\n",
            "  1.807151   1.62246672 2.70501351 2.61736143]\n",
            " [3.4001725  3.05291684 2.81239644 3.27391775 2.55269948 2.69429774\n",
            "  2.51149295 2.87845164 3.23864373 3.28949024]\n",
            " [2.94308273 2.35954942 2.29598506 2.66688479 2.48011823 2.39435039\n",
            "  2.31571212 2.5050168  3.24072057 3.50002115]]\n",
            "CUBLAS took 0.000677 seconds\n",
            "Maximum error 2.832987\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hewu-Bd0ywYX"
      },
      "source": [
        "**Using the PyOpenCL module**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs1xKGh8y51u"
      },
      "source": [
        "Open Computing Language (OpenCL) - это фреймворк, используемый для разработки программ, работающих\n",
        "на гетерогенных платформах, которые могут работать на ЦПУ или ГПУ,\n",
        "созданных разными производителями."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niIqY7xTzhun",
        "outputId": "5f808c1f-1439-463c-e070-efbbac67005d"
      },
      "source": [
        "!pip install pyopencl"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyopencl\n",
            "  Downloading pyopencl-2021.2.9-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (879 kB)\n",
            "\u001b[K     |████████████████████████████████| 879 kB 5.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: appdirs>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.4.4)\n",
            "Requirement already satisfied: pytools>=2021.2.7 in /usr/local/lib/python3.7/dist-packages (from pyopencl) (2021.2.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from pyopencl) (1.19.5)\n",
            "Installing collected packages: pyopencl\n",
            "Successfully installed pyopencl-2021.2.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2D7mjaPIzmGK",
        "outputId": "3b99c785-ffa3-49a6-d94f-f24f51abc7b5"
      },
      "source": [
        "import pyopencl as cl\n",
        "\n",
        "\n",
        "def print_device_info() :\n",
        "  print('\\n' + '=' * 60 + '\\nOpenCL Platforms and Devices')\n",
        "  for platform in cl.get_platforms():\n",
        "    print('=' * 60)\n",
        "    print('Platform - Name:  ' + platform.name)\n",
        "    print('Platform - Vendor:  ' + platform.vendor)\n",
        "    print('Platform - Version:  ' + platform.version)\n",
        "    print('Platform - Profile:  ' + platform.profile)\n",
        "\n",
        "    for device in platform.get_devices():\n",
        "      print('    ' + '-' * 56)\n",
        "      print('    Device - Name:  ' \\\n",
        "            + device.name)\n",
        "      print('    Device - Type:  ' \\\n",
        "            + cl.device_type.to_string(device.type))\n",
        "      print('    Device - Max Clock Speed:  {0} Mhz'\\\n",
        "            .format(device.max_clock_frequency))\n",
        "      print('    Device - Compute Units:  {0}'\\\n",
        "            .format(device.max_compute_units))\n",
        "      print('    Device - Local Memory:  {0:.0f} KB'\\\n",
        "            .format(device.local_mem_size/1024.0))\n",
        "      print('    Device - Constant Memory:  {0:.0f} KB'\\\n",
        "            .format(device.max_constant_buffer_size/1024.0))\n",
        "      print('    Device - Global Memory: {0:.0f} GB'\\\n",
        "            .format(device.global_mem_size/1073741824.0))\n",
        "      print('    Device - Max Buffer/Image Size: {0:.0f} MB'\\\n",
        "            .format(device.max_mem_alloc_size/1048576.0))\n",
        "      print('    Device - Max Work Group Size: {0:.0f}'\\\n",
        "            .format(device.max_work_group_size))\n",
        "  print('\\n')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  print_device_info()\n",
        "\t"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "OpenCL Platforms and Devices\n",
            "============================================================\n",
            "Platform - Name:  NVIDIA CUDA\n",
            "Platform - Vendor:  NVIDIA Corporation\n",
            "Platform - Version:  OpenCL 1.2 CUDA 11.2.109\n",
            "Platform - Profile:  FULL_PROFILE\n",
            "    --------------------------------------------------------\n",
            "    Device - Name:  Tesla K80\n",
            "    Device - Type:  ALL | GPU\n",
            "    Device - Max Clock Speed:  823 Mhz\n",
            "    Device - Compute Units:  13\n",
            "    Device - Local Memory:  48 KB\n",
            "    Device - Constant Memory:  64 KB\n",
            "    Device - Global Memory: 11 GB\n",
            "    Device - Max Buffer/Image Size: 2860 MB\n",
            "    Device - Max Work Group Size: 1024\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3JYtB1r9zt5K"
      },
      "source": [
        "**How to build a PyOpenCL application**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NOWeDbHK3vUy"
      },
      "source": [
        "Первым шагом для создания программы на PyOpenCL является\n",
        "кодирование приложения на основном хосте. Фактически, это выполняется на главном компьютере (как правило, на\n",
        "компьютере пользователя), а затем он отправляет приложение на подключенные устройства ГПУ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iIWZK-otztij",
        "outputId": "52b18529-e83e-46cf-8dcf-5dfaef2365d5"
      },
      "source": [
        "import numpy as np\n",
        "import pyopencl as cl\n",
        "import numpy.linalg as la\n",
        "\n",
        "vector_dimension = 100\n",
        "\n",
        "vector_a = np.random.randint(vector_dimension, size=vector_dimension, dtype=np.uint8)\n",
        "vector_b = np.random.randint(vector_dimension, size=vector_dimension, dtype=np.uint8)\n",
        "\n",
        "platform = cl.get_platforms()[0]\n",
        "device = platform.get_devices()[0]\n",
        "\n",
        "context = cl.Context([device])\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "mf = cl.mem_flags\n",
        "a_g = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
        "hostbuf=vector_a)\n",
        "b_g = cl.Buffer(context, mf.READ_ONLY | mf.COPY_HOST_PTR,\n",
        "hostbuf=vector_b)\n",
        "\n",
        "program = cl.Program(context, \"\"\"\n",
        "__kernel void vectorSum(__global const int *a_g, __global const int\n",
        "*b_g, __global int *res_g) {\n",
        "  int gid = get_global_id(0);\n",
        "  res_g[gid] = a_g[gid] + b_g[gid];\n",
        "}\n",
        "\"\"\").build()\n",
        "\n",
        "res_g = cl.Buffer(context, mf.WRITE_ONLY, vector_a.nbytes)\n",
        "program.vectorSum(queue, vector_a.shape, None, a_g, b_g, res_g)\n",
        "\n",
        "res_np = np.empty_like(vector_a, dtype=np.uint8)\n",
        "cl.enqueue_copy(queue, res_np, res_g)\n",
        "\n",
        "print(\"PyOPENCL SUM OF TWO VECTORS\")\n",
        "print(\"Platform Selected = %s\" %platform.name )\n",
        "print(\"Device Selected = %s\" %device.name)\n",
        "print(\"VECTOR LENGTH = %s\" %vector_dimension)\n",
        "print(\"INPUT VECTOR A\")\n",
        "print(vector_a)\n",
        "print(\"INPUT VECTOR B\")\n",
        "print(vector_b)\n",
        "print(\"OUTPUT VECTOR RESULT A + B \")\n",
        "print(res_np)\n",
        "\n",
        "assert(la.norm(res_np - (vector_a + vector_b))) < 1e-5"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyOPENCL SUM OF TWO VECTORS\n",
            "Platform Selected = NVIDIA CUDA\n",
            "Device Selected = Tesla K80\n",
            "VECTOR LENGTH = 100\n",
            "INPUT VECTOR A\n",
            "[23 65 98 78 41 29 79 90 20 16 98 74 12  9 58  0 94 90 37 98 78 43 40 46\n",
            " 19 30 95 32 52 91 22 21 65 14 70 14 24 13 93 66 16 34 80 99 60 18 44 44\n",
            " 36 92 55 57 29  6 74 86 84 55 10 44 75 43 29 65 73 99  7 80 55 92 64 70\n",
            " 16 80 85  3 56 52 13 40 23 45 38 94 18 41 63 71 65 36 23 15 86 36 31 40\n",
            " 97 50 75 78]\n",
            "INPUT VECTOR B\n",
            "[99 29 18 70 36 49 70 13 28  7  6 43 57 78 14 77 33 91 85 69 20 13 60 82\n",
            " 82 86 75 93 14 13 81 13 72 26 49 81 99 99 34 35 44 25  1 62 11 39 51 66\n",
            " 51 92 69 62 32 66 23 78  8 16 53 60 71 62  8 46 62 22 91  4 11  1 17  9\n",
            " 25 15 14 65 87 72 97 22 62 51 24  7 38 32 71 40 11 17 49 55 52 51 53 73\n",
            " 74 67 15 30]\n",
            "OUTPUT VECTOR RESULT A + B \n",
            "[122  94 116 148  77  78 149 103  48  23 104 117  69  87  72  77 127 181\n",
            " 122 167  98  56 100 128 101 116 170 125  66 104 103  34 137  40 119  95\n",
            " 123 112 127 101  60  59  81 161  71  57  95 110  87 184 124 119  61  72\n",
            "  97 164  92  71  63 104 146 105  37 111 135 121  98  84  66  93  81  79\n",
            "  41  95  99  68 143 124 110  62  85  96  62 101  56  73 134 111  76  53\n",
            "  72  70 138  87  84 113 171 117  90 108]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iyfdy4YH5r6K"
      },
      "source": [
        "**Evaluating element-wise expressions with\n",
        "PyOpenCL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-OJ-p-75_i-"
      },
      "source": [
        "Подобно PyCUDA, PyOpenCL предоставляет функциональные возможности\n",
        "класса pyopencl.elementwise, которые позволяют нам проводить вычисления над сложными выражениями за один вычислительный проход."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDuNVf3K52YC",
        "outputId": "9030cb35-76dd-44f7-a500-5d07d3198c96"
      },
      "source": [
        "import pyopencl as cl\n",
        "import pyopencl.array as cl_array\n",
        "import numpy as np\n",
        "\n",
        "context = cl.create_some_context()\n",
        "queue = cl.CommandQueue(context)\n",
        "\n",
        "vector_dimension = 100\n",
        "vector_a = cl_array.to_device(queue,  np.random.randint(vector_dimension, size=vector_dimension, dtype=np.uint8))\n",
        "vector_b = cl_array.to_device(queue,  np.random.randint(vector_dimension, size=vector_dimension, dtype=np.uint8))\n",
        "result_vector = cl_array.empty_like(vector_a)\n",
        "\n",
        "elementWiseSum = cl.elementwise.ElementwiseKernel(context, \"int *a, int *b, int *c\", \"c[i] = a[i] + b[i]\", \"sum\")\n",
        "elementWiseSum(vector_a, vector_b, result_vector)\n",
        "\n",
        "print(\"PyOpenCL ELEMENTWISE SUM OF TWO VECTORS\")\n",
        "print(\"VECTOR LENGTH = %s\" %vector_dimension)\n",
        "print(\"INPUT VECTOR A\")\n",
        "print(vector_a)\n",
        "print(\"INPUT VECTOR B\")\n",
        "print(vector_b)\n",
        "print(\"OUTPUT VECTOR RESULT A + B \")\n",
        "print(result_vector)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyOpenCL ELEMENTWISE SUM OF TWO VECTORS\n",
            "VECTOR LENGTH = 100\n",
            "INPUT VECTOR A\n",
            "[30 72 81 34 11 75 63 12 37 82 20 42 66 64  9 29 34 20 63 57  9 40 48 33\n",
            " 75 42 20 49 55 90 95 92 54 99 28 21 61 23 14 27 68  8 41  3 33 18 90 44\n",
            "  2 98 79 96 18 67 64 47 34 16 99 78 97 98 33 48  8 74 18  3  7 28 49 82\n",
            " 43 38 24 56 43  4 57 79 26  8 60 23 12 41 11 67  7 90 17 26 38 79 69 68\n",
            " 29 70 31 15]\n",
            "INPUT VECTOR B\n",
            "[90 40 70 26 58 25 72 52 67  6 97 95  8 53 29  3 12 79 80 88  8 43 52 16\n",
            " 56  9  0 48 48 63 45 95 18 17 52 76 83 13 92  2 48 71 91  4 15 80 75 41\n",
            " 66 68 10 42 28  0 51 16 37 98  2 92 10 76 69 82 12 33  7 31 42 97 74 84\n",
            " 75 35 32 67 51 95 64 85 77 33 92 69 59 12 64 49 92 40 77 84 69 35 78 19\n",
            " 18 81  4 44]\n",
            "OUTPUT VECTOR RESULT A + B \n",
            "[120 112 151  60  69 100 135  64 104  88 117 137  74 117  38  32  46  99\n",
            " 143 145  17  83 100  49 131  51  20  97 103 153 140 187  72 116  80  97\n",
            " 144  36 106  29 116  79 132   7  48  98 165  85  68 166  89 138  46  67\n",
            " 115  63  71 114 101 170 107 174 102 130  20 107  25  34  49 125 123 166\n",
            " 118  73  56 123  94  99 121 164 103  41 152  92  71  53  75 116  99 130\n",
            "  94 110 107 114 147  87  47 151  35  59]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3RH8YLs6Lua"
      },
      "source": [
        "**Testing your GPU application with PyOpenCL**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lArRgObQ7EXb"
      },
      "source": [
        "В данном примере выполняется оценка и сравнения времени вычисления суммы двух\n",
        "векторов с элементами, представленными в виде чисел с плавающей точкой. Для\n",
        "сравнения, одна и та же операция была реализована в двух отдельных функциях.\n",
        "Первая функция использует только ЦПУ, в то время как вторая написана с использованием PyOpenCL и использует ГПУ для вычислений."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CVjnPovI-YkN"
      },
      "source": [
        "Как можно видеть из результата, скорость вычисление на ГПУ значительно превосходят вычисления на ЦПУ для решения данной задачи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fQISPwUD6Lh5",
        "outputId": "700c5d1e-faaf-440c-b91c-ce7f98f87b39"
      },
      "source": [
        "from time import time\n",
        "import pyopencl as cl\n",
        "import numpy as np\n",
        "import numpy.linalg as la\n",
        "\n",
        "a = np.random.rand(10000).astype(np.float32)\n",
        "b = np.random.rand(10000).astype(np.float32)\n",
        "\n",
        "def test_cpu_vector_sum(a, b):\n",
        "  c_cpu = np.empty_like(a)\n",
        "  cpu_start_time = time()\n",
        "  for i in range(10000):\n",
        "    for j in range(10000):\n",
        "      c_cpu[i] = a[i] + b[i]\n",
        "  cpu_end_time = time()\n",
        "  print(\"CPU Time: {0} s\".format(cpu_end_time - cpu_start_time))\n",
        "  return c_cpu\n",
        "\n",
        "def test_gpu_vector_sum(a, b):\n",
        "  platform = cl.get_platforms()[0]\n",
        "  device = platform.get_devices()[0]\n",
        "  context = cl.Context([device])\n",
        "  queue = cl.CommandQueue(context, properties=cl.command_queue_properties.PROFILING_ENABLE)\n",
        "\n",
        "  a_buffer = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=a)\n",
        "  b_buffer = cl.Buffer(context, cl.mem_flags.READ_ONLY | cl.mem_flags.COPY_HOST_PTR, hostbuf=b)\n",
        "  c_buffer = cl.Buffer(context, cl.mem_flags.WRITE_ONLY, b.nbytes)\n",
        "\n",
        "  program = cl.Program(context, \"\"\"\n",
        "  __kernel void sum(__global const float *a,\n",
        "                    __global const float *b,\n",
        "                    __global float *c)\n",
        "  {\n",
        "      int i = get_global_id(0);\n",
        "      int j;\n",
        "      for(j = 0; j < 10000; j++)\n",
        "      {\n",
        "          c[i] = a[i] + b[i];\n",
        "      }\n",
        "  }\"\"\").build()\n",
        "\n",
        "  gpu_start_time = time()\n",
        "  event = program.sum(queue, a.shape, None, a_buffer, b_buffer, c_buffer)\n",
        "  event.wait()\n",
        "  elapsed = 1e-9*(event.profile.end - event.profile.start)\n",
        "  print(\"GPU Kernel evaluation Time: {0} s\".format(elapsed))\n",
        "  c_gpu = np.empty_like(a)\n",
        "  cl._enqueue_read_buffer(queue, c_buffer, c_gpu).wait()\n",
        "  gpu_end_time = time()\n",
        "  print(\"GPU Time: {0} s\".format(gpu_end_time - gpu_start_time))\n",
        "\n",
        "  return c_gpu\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  cpu_result = test_cpu_vector_sum(a, b)\n",
        "  gpu_result = test_gpu_vector_sum(a, b)\n",
        "  assert (la.norm(cpu_result - gpu_result)) < 1e-5"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU Time: 47.169475078582764 s\n",
            "GPU Kernel evaluation Time: 0.0068231360000000005 s\n",
            "GPU Time: 0.009328126907348633 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SktRNiw_7xW7"
      },
      "source": [
        "**Выводы:**\n",
        "\n",
        "В ходе лабораторной работы было рассмотрено выполнение распределенных вычислений, а также архитектура модели памяти на графических процессорах поддерживающих технологию CUDA от NVIDA. Продемонстрировано взаимодействие с графическими процессорами с помощью библиотек PyCUDA, Numba, PyOpenCL. Было проведено тестирование и оценка использования вычислений на графических процессорах над различными математическими операциями."
      ]
    }
  ]
}